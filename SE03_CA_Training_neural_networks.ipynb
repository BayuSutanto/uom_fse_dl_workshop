{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxVkR2M74ZRt"
      },
      "source": [
        "![](https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/se_03.png)\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CLDiego/uom_fse_dl_workshop/blob/main/SE03_CA_Training_neural_networks.ipynb)\n",
        "# Workshop Instructions\n",
        "***\n",
        "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/write.svg\" width=\"20\"/> Follow along by typing the code yourself - this helps with learning!\n",
        "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/code.svg\" width=\"20\"/> Code cells marked as \"Exercise\" are for you to complete\n",
        "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/reminder.svg\" width=\"20\"/> Look for hints if you get stuck\n",
        "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/success.svg\" width=\"20\" /> Compare your solution with the provided answers\n",
        "- <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/list.svg\" width=\"20\" /> Don't worry if you make mistakes - debugging is part of learning!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRQ5WLFk4ZRx",
        "outputId": "8ec75138-57b7-4a10-993d-3d93e6a7514b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "colab_utils.txt     100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
            "utils/__init__.py   100%[===================>]   1.75K  --.-KB/s    in 0s      \n",
            "utils/__version__.p 100%[===================>]     234  --.-KB/s    in 0s      \n",
            "utils/core.py       100%[===================>]  55.36K  --.-KB/s    in 0.009s  \n",
            "utils/quizzes.json  100%[===================>]  18.63K  --.-KB/s    in 0s      \n",
            "utils/solutions.jso 100%[===================>]  45.93K  --.-KB/s    in 0.002s  \n",
            "utils/data/__init__ 100%[===================>]     766  --.-KB/s    in 0s      \n",
            "utils/data/datasets 100%[===================>]   8.36K  --.-KB/s    in 0s      \n",
            "utils/data/download 100%[===================>]  11.24K  --.-KB/s    in 0s      \n",
            "utils/data/uwmgi.py 100%[===================>]  11.78K  --.-KB/s    in 0s      \n",
            "utils/ml/__init__.p 100%[===================>]     526  --.-KB/s    in 0s      \n",
            "utils/ml/metrics.py 100%[===================>]   3.60K  --.-KB/s    in 0s      \n",
            "utils/ml/scaling.py 100%[===================>]   4.77K  --.-KB/s    in 0s      \n",
            "utils/ml/training.p 100%[===================>]   8.25K  --.-KB/s    in 0s      \n",
            "utils/plotting/__in 100%[===================>]   1.59K  --.-KB/s    in 0s      \n",
            "utils/plotting/font 100%[===================>]   2.53K  --.-KB/s    in 0s      \n",
            "utils/plotting/form 100%[===================>]  12.42K  --.-KB/s    in 0s      \n",
            "utils/plotting/inte 100%[===================>]  16.23K  --.-KB/s    in 0s      \n",
            "utils/plotting/plot 100%[===================>]  22.75K  --.-KB/s    in 0s      \n"
          ]
        }
      ],
      "source": [
        "# Download utils from GitHub\n",
        "!wget -q --show-progress https://raw.githubusercontent.com/CLDiego/uom_fse_dl_workshop/main/colab_utils.txt -O colab_utils.txt\n",
        "!wget -q --show-progress -x -nH --cut-dirs=3 -i colab_utils.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1eVkonh4ZRy",
        "outputId": "d55a8ed6-3bcb-4f37-8add-72b93ecb9551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faculty of Science and Engineering ðŸ”¬\n",
            "\u001b[95mThe University of Manchester \u001b[0m\n",
            "Invoking utils version: \u001b[92m1.1.0+4edc6ee\u001b[0m\n",
            "GPU available: True\n",
            "GPU device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "repo_path = Path.cwd()\n",
        "if str(repo_path) not in sys.path:\n",
        "    sys.path.append(str(repo_path))\n",
        "\n",
        "import utils\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "print(\"GPU available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU device:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"No GPU available. Please ensure you've enabled GPU in Runtime > Change runtime type\")\n",
        "\n",
        "checker = utils.core.ExerciseChecker(\"SE03\")\n",
        "quizzer = utils.core.QuizManager(\"SE03\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBhSrln-4ZRy"
      },
      "source": [
        "# 1. PyTorch workflow\n",
        "***\n",
        "The previous session we had a look at the basics of neural networks and how to train a single layer perceptron. In this session we will look at the PyTorch framework and how to use it to build and train neural networks.\n",
        "\n",
        "Most deep learning projects follow a similar workflow. The following figure illustrates the typical workflow of a PyTorch project:\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/pytorch_workflow.png\" width=\"80%\">\n",
        "</div>\n",
        "\n",
        "The workflow consists of the following steps:\n",
        "\n",
        "| Step | Description |\n",
        "|------|----------|\n",
        "| Obtain Data | Collect and preprocess the data for training and testing |\n",
        "| Prepare Data | Setup data in PyTorch format |\n",
        "| Pre-process Data | Normalize and augment the data. This may involve data cleaning, normalization, and splitting the data into training, validation, and test sets. |\n",
        "| Activation Function | Choose an activation function for the model. This may involve selecting a suitable activation function for the model, such as ReLU, sigmoid, or tanh. |\n",
        "| Model | Define the model architecture. |\n",
        "| Choose optimiser | Select an optimiser for the model. |\n",
        "| Choose loss function | Select a loss function for the model. |\n",
        "| Create training loop | Define the training steps, including forward pass, backward pass, and parameter updates. |\n",
        "| Fit model | Train the model using the training data. |\n",
        "| Evaluate model | Evaluate the model using the validation and test data to make predictions |\n",
        "| Improve model | Fine-tune the model by adjusting hyperparameters, adding regularization, or modifying the architecture. |\n",
        "| Save or deploy model | Save the trained model for future use or deploy it in a production environment. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwDoehce4ZRz"
      },
      "source": [
        "## Step 1: Obtain Data\n",
        "***\n",
        "In this notebook we are going to be using the [ARKOMA dataset](https://www.sciencedirect.com/science/article/pii/S2352340923007989). The dataset is intended to be used as a benchmark for the creation of Neural Networks to perform inverse kinematics for robotic arms using a NAO robot. The dataset contains data for two different robotic arms: the left arm and the right arm. The data is generated using a physics engine that simulates the movement of the robotic arms in a 3D environment. The dataset contain 10,000 input-output data pairs for both arms. The input data is the end-effector position of the robotic arm, and the output data is the joint angles of the robotic arm.\n",
        "\n",
        "The input parameters are:\n",
        "\n",
        "| Notation | Description |\n",
        "|------|----------|\n",
        "| $ P_{x} $ | The end-effector position with respect to the torso's x-axis |\n",
        "| $ P_{y} $ | The end-effector position with respect to the torso's y-axis |\n",
        "| $ P_{z} $ | The end-effector position with respect to the torso's z-axis |\n",
        "| $ R_{x} $ | The end-effector orientation relative to the torso's x-axis |\n",
        "| $ R_{y} $ | The end-effector orientation relative to the torso's y-axis |\n",
        "| $ R_{z} $ | The end-effector orientation relative to the torso's z-axis |\n",
        "\n",
        "The output parameters are:\n",
        "\n",
        "| Notation | Left Arm Joint | Left Arm Range(rad) | Right Arm Joint | Right Arm Range(rad) |\n",
        "|----------|----------------|--------------------|-----------------|--------------------|\n",
        "| $ \\theta_{1} $ | LShoulder Pitch | [-2.0857, 2.0857] | RShoulder Pitch | [-2.0857, 2.0857] |\n",
        "| $ \\theta_{2} $ | LShoulder Roll | [-0.3142, 1.3265] | RShoulder Roll | [-1.3265, 0.3142] |\n",
        "| $ \\theta_{3} $ | LElbow Yaw | [-2.0857, 2.0857] | RElbow Yaw | [-2.0857, 2.0857] |\n",
        "| $ \\theta_{4} $ | LElbow Roll | [-1.5446, 0.0349] | RElbow Roll | [-0.0349, 1.5446] |\n",
        "| $ \\theta_{5} $ | LWrist Yaw | [-1.8238, 1.8238] | RWrist Yaw | [-1.8238, 1.8238]  |\n",
        "\n",
        "In this notebook, we are going to focus on the right arm. The data is stored in CSV format. To load the data, we will use the `pandas` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuhLFjoa4ZRz",
        "outputId": "35a4ff7c-1ead-4e11-b6b4-3102be1793b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading:\n",
            "ARKOMA: The Dataset to Build Neural Networks-Based Inverse Kinematics for NAO Robot Arms\n",
            "> Authors: Arif Nugroho, Eko Mulyanto Yuniarno, Mauridhi Hery Purnomo\n",
            "> Year: 2020\n",
            "> Website: https://www.sciencedirect.com/science/article/pii/S2352340923007989\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading brg4dz8nbb-1.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 658k/658k [00:00<00:00, 967kiB/s] \n",
            "Extracting brg4dz8nbb-1.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 334.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed compressed file: /content/datasets/brg4dz8nbb-1.zip\n",
            "Found nested archive: Dataset on NAO Robot Arms.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset on NAO Robot Arms.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 1154.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed compressed file: /content/datasets/brg4dz8nbb-1/Dataset on NAO Robot Arms.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "data_path = Path(Path.cwd(), 'datasets')\n",
        "dataset_path = utils.data.download_dataset('ARKOMA',\n",
        "                                   dest_path=data_path,\n",
        "                                   extract=True,\n",
        "                                   remove_compressed=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nOqjZw734ZRz"
      },
      "outputs": [],
      "source": [
        "# Set the path to the datasets (already provided above)\n",
        "right_arm_path = dataset_path / 'Right Arm Dataset'\n",
        "\n",
        "# Create file paths using a dictionary comprehension and format strings\n",
        "file_parts = ['Train', 'Val', 'Test']\n",
        "dataset_files = {\n",
        "    part: {\n",
        "        'features': right_arm_path / f'R{part}_x.csv',\n",
        "        'targets': right_arm_path / f'R{part}_y.csv'\n",
        "    } for part in file_parts\n",
        "}\n",
        "\n",
        "# Unpack into individual variables for compatibility with existing code\n",
        "feats_train = dataset_files['Train']['features']\n",
        "targets_train = dataset_files['Train']['targets']\n",
        "feats_val = dataset_files['Val']['features']\n",
        "targets_val = dataset_files['Val']['targets']\n",
        "feats_test = dataset_files['Test']['features']\n",
        "targets_test = dataset_files['Test']['targets']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA93rIou4ZR0"
      },
      "source": [
        "## Step 2 and 3: Prepare and Pre-process Data\n",
        "***\n",
        "The next step is to pre-process the data. This involves normalizing the data and splitting it into training, validation, and test sets.\n",
        "\n",
        "### Training, Validation, and Test Sets\n",
        "***\n",
        "One of the crucial steps in machine learning is to split the data into training, validation, and test sets. Each of these sets serves a specific purpose in the model development process:\n",
        "\n",
        "| Dataset | Purpose | Typical Split | Usage | Analogy |\n",
        "|---------|---------|---------------|--------|----------|\n",
        "| Training Set | Used to train the model by adjusting weights and biases through backpropagation | 60-80% | Every training iteration | Like studying materials to learn a subject |\n",
        "| Validation Set | Used to tune hyperparameters and monitor model performance during training to prevent overfitting | 10-20% | During model development | Like practice exams to gauge learning progress |\n",
        "| Test Set | Used only once for final model evaluation; never used for training or tuning | 10-20% | Once, after training | Like a final exam with new, unseen questions |\n",
        "\n",
        "The ARKOMA dataset has already been split into these three sets for us, which simplifies our workflow.\n",
        "\n",
        "> <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/reminder.svg\" width=\"20\"/>  **Note**: The test set is our generalisation benchmark. It is important to keep the test set separate from the training and validation sets to ensure that the model's performance is evaluated on unseen data. This helps us understand how well the model will perform in real-world scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZYhVZGP4ZR0",
        "outputId": "8e9643ae-18fd-4a41-f5d9-ef5e1d870c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (6000, 6) | y_train shape: (6000, 5)\n",
            "X_test shape: (2000, 6) | y_test shape: (2000, 5)\n",
            "X_val shape: (2000, 6) | y_val shape: (2000, 5)\n"
          ]
        }
      ],
      "source": [
        "# Load the datasets\n",
        "# Training set\n",
        "X_train = pd.read_csv(feats_train)\n",
        "y_train = pd.read_csv(targets_train)\n",
        "# Test set\n",
        "X_test = pd.read_csv(feats_test)\n",
        "y_test = pd.read_csv(targets_test)\n",
        "# Validation set\n",
        "X_val = pd.read_csv(feats_val)\n",
        "y_val = pd.read_csv(targets_val)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape} | y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape} | y_test shape: {y_test.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape} | y_val shape: {y_val.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LYTo47rK4ZR1",
        "outputId": "dca85989-ae73-4e08-a009-5faf81685d6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Px      Py      Pz     Rx     Ry     Rz\n",
              "0  116.12 -180.97  198.59 -10.39 -41.23   5.04\n",
              "1   83.41 -228.19  -25.54  24.58  52.19 -43.12\n",
              "2   45.81 -187.38  285.07   2.08 -81.96  -9.99\n",
              "3  112.87 -146.16  -74.21 -19.96  56.73  13.66\n",
              "4  175.85 -162.01   41.35 -21.91   5.63  10.07"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a626789-7aad-4677-a240-f3b3f48cd5c0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Px</th>\n",
              "      <th>Py</th>\n",
              "      <th>Pz</th>\n",
              "      <th>Rx</th>\n",
              "      <th>Ry</th>\n",
              "      <th>Rz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>116.12</td>\n",
              "      <td>-180.97</td>\n",
              "      <td>198.59</td>\n",
              "      <td>-10.39</td>\n",
              "      <td>-41.23</td>\n",
              "      <td>5.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>83.41</td>\n",
              "      <td>-228.19</td>\n",
              "      <td>-25.54</td>\n",
              "      <td>24.58</td>\n",
              "      <td>52.19</td>\n",
              "      <td>-43.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45.81</td>\n",
              "      <td>-187.38</td>\n",
              "      <td>285.07</td>\n",
              "      <td>2.08</td>\n",
              "      <td>-81.96</td>\n",
              "      <td>-9.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>112.87</td>\n",
              "      <td>-146.16</td>\n",
              "      <td>-74.21</td>\n",
              "      <td>-19.96</td>\n",
              "      <td>56.73</td>\n",
              "      <td>13.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>175.85</td>\n",
              "      <td>-162.01</td>\n",
              "      <td>41.35</td>\n",
              "      <td>-21.91</td>\n",
              "      <td>5.63</td>\n",
              "      <td>10.07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a626789-7aad-4677-a240-f3b3f48cd5c0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a626789-7aad-4677-a240-f3b3f48cd5c0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a626789-7aad-4677-a240-f3b3f48cd5c0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3485740e-8a02-4915-b1dd-4e7c1759bf06\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3485740e-8a02-4915-b1dd-4e7c1759bf06')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3485740e-8a02-4915-b1dd-4e7c1759bf06 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train",
              "summary": "{\n  \"name\": \"X_train\",\n  \"rows\": 6000,\n  \"fields\": [\n    {\n      \"column\": \"Px\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 76.20465890209003,\n        \"min\": -149.87,\n        \"max\": 218.63,\n        \"num_unique_values\": 5310,\n        \"samples\": [\n          31.69,\n          90.29,\n          149.27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Py\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52.5663717007181,\n        \"min\": -315.85,\n        \"max\": 30.44,\n        \"num_unique_values\": 5119,\n        \"samples\": [\n          -149.92,\n          -174.3,\n          -53.18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pz\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 124.44337162960618,\n        \"min\": -115.24,\n        \"max\": 319.08,\n        \"num_unique_values\": 5571,\n        \"samples\": [\n          233.03,\n          198.29,\n          242.01\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47.115683008875685,\n        \"min\": -164.68,\n        \"max\": 179.42,\n        \"num_unique_values\": 4942,\n        \"samples\": [\n          107.38,\n          56.96,\n          -44.06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ry\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55.69118799922691,\n        \"min\": -171.43,\n        \"max\": 166.35,\n        \"num_unique_values\": 5198,\n        \"samples\": [\n          -64.0,\n          -2.66,\n          6.98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rz\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.7152809462459,\n        \"min\": -153.66,\n        \"max\": 157.1,\n        \"num_unique_values\": 4529,\n        \"samples\": [\n          -12.2,\n          69.7,\n          -90.32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "source": [
        "# @title Py\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "X_train['Py'].plot(kind='line', figsize=(8, 4), title='Py')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "QmgFCx216-bY",
        "outputId": "7f273df8-306c-40aa-9002-4176cf1b335f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc5RUeq14ZR1"
      },
      "outputs": [],
      "source": [
        "y_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ryjuc0N4ZR1"
      },
      "source": [
        "### Normalisation\n",
        "***\n",
        "Normalisation is a crucial step in the pre-processing of data for machine learning models. It involves scaling the input features to a similar range, which helps improve the convergence speed and performance of the model. In this notebook, we will use Min-Max normalization to scale the input features to a range of [0, 1]. The formula for Min-Max normalization is as follows:\n",
        "$$ X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}} $$\n",
        "\n",
        "Where:\n",
        "- $ X_{norm} $ is the normalized value.\n",
        "- $ X$ is the original value.\n",
        "- $ X_{min} $ is the minimum value of the feature.\n",
        "- $ X_{max} $ is the maximum value of the feature.\n",
        "\n",
        "The normalisation parameters will be computed from the training set and then applied to the validation and test sets. This helps to prevent data leakage and ensures that the model is evaluated on unseen data.\n",
        "\n",
        "| Benefit | Description | Impact on Training |\n",
        "|---------|-------------|-------------------|\n",
        "| **Faster Convergence** | Normalized inputs lead to better-conditioned optimization | Reduces training time |\n",
        "| **Numerical Stability** | Prevents extremely large or small values | Reduces risk of gradient explosions/vanishing |\n",
        "| **Feature Scaling** | Makes all features contribute equally to the model | Prevents certain features from dominating |\n",
        "| **Better Generalization** | Helps models transfer between different images | Improves performance on unseen data |\n",
        "\n",
        "***\n",
        "\n",
        "> <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/code.svg\" width=\"20\"/> **Snippet 1**: Normalisation using Min-Max scaling\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler on the training data\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Transform the training\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "\n",
        "# Inverse transform the scaled data to get the original values\n",
        "X_train_original = scaler.inverse_transform(X_train_scaled)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHb5IbXL4ZR1",
        "outputId": "95843e47-6688-4dfc-d639-2bbcea8f1f31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train normalized range: [0.0000, 1.0000]\n",
            "y_train normalized range: [0.0000, 1.0000]\n",
            "--------------------------------------------------------------------------------\n",
            "âœ… X_train_tensor is correct!\n",
            "âœ… y_train_tensor is correct!\n",
            "âœ… X_train_scaled is correct!\n",
            "âœ… y_train_scaled is correct!\n",
            "âœ… scale_range_min is correct!\n",
            "âœ… scale_range_max is correct!\n",
            "\n",
            "ðŸŽ‰ Excellent! All parts are correct!\n"
          ]
        }
      ],
      "source": [
        "# Exercise 1: Data Loading and Preprocessing ðŸŽ¯\n",
        "\n",
        "# Create PyTorch tensors from the training, validation, and test data\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "# Create MinMaxScalers for feature and target normalization\n",
        "x_scaler = MinMaxScaler()\n",
        "y_scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scalers on training data\n",
        "x_scaler = x_scaler.fit(X_train_tensor)\n",
        "y_scaler = y_scaler.fit(y_train_tensor)\n",
        "\n",
        "\n",
        "# Transform all datasets and put them into tensors\n",
        "X_train_scaled = torch.tensor(x_scaler.transform(X_train_tensor), dtype=torch.float32)\n",
        "X_val_scaled = torch.tensor(x_scaler.transform(X_val_tensor), dtype=torch.float32)\n",
        "X_test_scaled = torch.tensor(x_scaler.transform(X_test_tensor), dtype=torch.float32)\n",
        "\n",
        "\n",
        "y_train_scaled = torch.tensor(y_scaler.transform(y_train_tensor), dtype=torch.float32)\n",
        "y_val_scaled = torch.tensor(y_scaler.transform(y_val_tensor), dtype=torch.float32)\n",
        "y_test_scaled = torch.tensor(y_scaler.transform(y_test_tensor), dtype=torch.float32)\n",
        "\n",
        "# Check the normalized data range\n",
        "print(f\"X_train normalized range: [{X_train_scaled.min().item():.4f}, {X_train_scaled.max().item():.4f}]\")\n",
        "print(f\"y_train normalized range: [{y_train_scaled.min().item():.4f}, {y_train_scaled.max().item():.4f}]\")\n",
        "\n",
        "# âœ… Check your answer\n",
        "answer = {\n",
        "    'X_train_tensor': X_train_tensor,\n",
        "    'y_train_tensor': y_train_tensor,\n",
        "    'X_train_scaled': X_train_scaled,\n",
        "    'y_train_scaled': y_train_scaled,\n",
        "    'scale_range_min': X_train_scaled.min().item(),\n",
        "    'scale_range_max': X_train_scaled.max().item(),\n",
        "}\n",
        "checker.check_exercise(1, answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F4oFWHZ4ZR2"
      },
      "source": [
        "## Step 4: Activation Function\n",
        "***\n",
        "The next step is to choose an activation function for the model. The activation function introduces non-linearity to the model, allowing it to learn complex relationships in the data. The following table lists some common activation functions used in neural networks, along with their characteristics and best use cases:\n",
        "\n",
        "| Function | Formula | Range | PyTorch Implementation | Best Used For |\n",
        "|----------|---------|-------|-------------------|---------------|\n",
        "| ReLU | $\\displaystyle f(x) = \\max(0, x)$ | $\\displaystyle [0, \\infty)$ | `torch.nn.ReLU()` | Hidden layers in most networks |\n",
        "| Sigmoid | $\\displaystyle f(x) = \\frac{1}{1+e^{-x}}$ | $\\displaystyle (0, 1)$ | `torch.nn.Sigmoid()` | Binary classification, gates in LSTMs |\n",
        "| Tanh | $\\displaystyle f(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$ | $\\displaystyle (-1, 1)$ | `torch.nn.Tanh()` | Hidden layers when output normalization is needed |\n",
        "| Leaky ReLU | $\\displaystyle f(x) = \\max(\\alpha x, x)$ | $\\displaystyle (-\\infty, \\infty)$ | `torch.nn.LeakyReLU(negative_slope=0.01)` | Preventing \"dead neurons\" problem |\n",
        "| Softmax | $\\displaystyle f(x_i) = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}}$ | $\\displaystyle (0, 1)$ | `torch.nn.Softmax(dim=1)` | Multi-class classification output layer |\n",
        "\n",
        "The choice of activation function depends on the specific problem and the architecture of the neural network.\n",
        "\n",
        "> <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/reminder.svg\" width=\"20\"/> **Tips**:\n",
        "> - ReLU is the most commonly used activation function in hidden layers of deep networks due to its simplicity and effectiveness.\n",
        "> - The activation function for the output layer depends on the type of problem being solved (e.g., regression, binary classification, multi-class classification).\n",
        "***\n",
        "> <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/list.svg\" width=\"20\"/> **Common Mistakes to Avoid**:\n",
        "> - Mixing activation functions in the same layer (e.g., using ReLU and sigmoid together) can lead to unexpected behavior.\n",
        "> - Using activation functions that saturate (like sigmoid) in hidden layers can lead to vanishing gradients, making training difficult.\n",
        "> - Forgetting to apply the activation function to the output layer can lead to incorrect predictions (e.g., not using softmax for multi-class classification).\n",
        "> - Not considering the range of the output when choosing the activation function (e.g., using sigmoid for regression tasks)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy5RsgG-4ZR2",
        "outputId": "f97dd348-fc90-4290-e4f4-ee456b35dc49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§  Quiz 1: Choosing the right activation function\n",
            "--------------------------------------------------------------------------------\n",
            "ðŸ“‹ Activation Functions Quiz\n",
            "--------------------------------------------------------------------------------\n",
            "For a regression problem like predicting the robot arm joint angles, which activation function would be most appropriate for the output layer?\n",
            "\n",
            "A. Sigmoid - to constrain all outputs between 0 and 1\n",
            "\n",
            "B. ReLU - to ensure no negative values in the output\n",
            "\n",
            "C. Linear (no activation) - to allow any numeric output value\n",
            "\n",
            "D. Softmax - to convert outputs into probability distributions\n",
            "\n",
            "E. Tanh - to constrain all outputs between -1 and 1\n",
            "\n",
            "Enter your answer (A, B, C, etc.): B\n",
            "\n",
            "âŒ Incorrect. The correct answer is C.\n",
            "\n",
            "ðŸ“š Explanation:\n",
            "For regression problems, where we need to predict continuous values like joint\n",
            "angles, the linear activation (or no activation) is most appropriate for the\n",
            "output layer. This is because:  1. Regression outputs need the full range of\n",
            "possible values, not constrained to intervals like [0,1] (sigmoid) or [-1,1]\n",
            "(tanh). 2. Joint angles can be positive or negative, so ReLU (which outputs only\n",
            "positive values) would be too restrictive. 3. Softmax is for multi-class\n",
            "classification problems, not regression.  Hidden layers in the network can and\n",
            "should use non-linear activations like ReLU, Tanh, or Leaky ReLU to capture\n",
            "complex relationships, but the output layer in regression tasks typically uses\n",
            "linear activation to predict any real-valued output.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ðŸ§  Quiz 2: Combining activation functions\n",
            "--------------------------------------------------------------------------------\n",
            "ðŸ“‹ Neural Network Architecture Quiz\n",
            "--------------------------------------------------------------------------------\n",
            "When designing a neural network for the robot arm inverse kinematics problem, which combination of activation functions would likely work best?\n",
            "\n",
            "A. Hidden layers: Sigmoid, Output layer: Sigmoid\n",
            "\n",
            "B. Hidden layers: ReLU, Output layer: Linear\n",
            "\n",
            "C. Hidden layers: Linear, Output layer: ReLU\n",
            "\n",
            "D. Hidden layers: Softmax, Output layer: Tanh\n",
            "\n",
            "E. Hidden layers: Tanh, Output layer: Softmax\n",
            "\n",
            "Enter your answer (A, B, C, etc.): C\n",
            "\n",
            "âŒ Incorrect. The correct answer is B.\n",
            "\n",
            "ðŸ“š Explanation:\n",
            "The best combination for this regression task is:  Hidden layers: ReLU - ReLU\n",
            "(Rectified Linear Unit) works well in hidden layers because: 1. It helps\n",
            "mitigate the vanishing gradient problem that can occur with sigmoid/tanh 2. It\n",
            "introduces non-linearity needed to learn complex patterns 3. It's\n",
            "computationally efficient 4. It's widely used in modern neural networks with\n",
            "proven success  Output layer: Linear - Linear activation is appropriate for the\n",
            "output layer in regression tasks because: 1. It allows the model to predict any\n",
            "numerical value within the range of joint angles 2. Joint angles can be positive\n",
            "or negative values 3. The model needs to predict exact values, not probabilities\n",
            "or classifications  Sigmoid and tanh would constrain outputs inappropriately,\n",
            "while softmax is designed for multi-class classification problems.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nðŸ§  Quiz 1: Choosing the right activation function\")\n",
        "quizzer.run_quiz(1)\n",
        "\n",
        "print(\"\\nðŸ§  Quiz 2: Combining activation functions\")\n",
        "quizzer.run_quiz(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnZLaC1z4ZR2"
      },
      "source": [
        "\n",
        "## Step 5: Model\n",
        "***\n",
        "The next step is to define the model architecture. In order to create a Neural Network we need to stack multiple neurons together. This is known as a **layer**. A layer is a collection of neurons that work together to process the input data. A simple ANN is formed by three types of layers:\n",
        "   - **Input Layer**: Receives the input data.\n",
        "   - **Hidden Layers**: Intermediate layers that process the data.\n",
        "   - **Output Layer**: Produces the final output.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/layers.png\" width=\"35%\">\n",
        "</div>\n",
        "\n",
        "\n",
        "The following table summarises the different types of layers available in PyTorch:\n",
        "\n",
        "| Layer Type | Class | Description | Common Uses |\n",
        "|------------|-------|-------------|------------|\n",
        "| Fully Connected | `torch.nn.Linear(in_features, out_features)` | Standard dense layer | Classification, regression |\n",
        "| Convolutional | `torch.nn.Conv2d(in_channels, out_channels, kernel_size)` | Spatial feature extraction | Image processing |\n",
        "| Recurrent | `torch.nn.RNN(input_size, hidden_size)` | Sequential data processing | Time series, text |\n",
        "| LSTM | `torch.nn.LSTM(input_size, hidden_size)` | Long-term dependencies | Complex sequences |\n",
        "| Embedding | `torch.nn.Embedding(num_embeddings, embedding_dim)` | Word vector representations | NLP tasks |\n",
        "| BatchNorm | `torch.nn.BatchNorm2d(num_features)` | Normalizes layer inputs | Training stability |\n",
        "| Dropout | `torch.nn.Dropout(p=0.5)` | Randomly zeros elements | Regularization |\n",
        "\n",
        "The choice of layer type depends on the specific problem and the architecture of the neural network. For example, convolutional layers are commonly used in image processing tasks, while recurrent layers are used for sequential data processing.\n",
        "\n",
        "### Number of Layers and Neurons\n",
        "***\n",
        "The number of layers and neurons in each layer is a hyperparameter that needs to be tuned. The following table summarises the common practices for choosing the number of layers and neurons:\n",
        "\n",
        "| Layer Type | Common Practices |\n",
        "|----------------|------------------|\n",
        "| Input Layer | Number of neurons = number of input features |\n",
        "| Hidden Layers | 1-3 hidden layers are common for most tasks. More complex tasks may require more layers. |\n",
        "| Output Layer | Number of neurons = number of output features (e.g., 1 for regression, number of classes for classification) |\n",
        "| Number of Neurons | Common practices: 2^n, where n is the number of layers. A common practice is to start with a number of neurons equal to the number of input features and then reduce the number of neurons in each subsequent layer. |\n",
        "\n",
        "***\n",
        "\n",
        "> <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/reminder.svg\" width=\"20\" /> **Tips**:\n",
        "> - Start with a simple architecture and gradually increase complexity as needed.\n",
        "> - The number of neurons in each layer can be adjusted based on the complexity of the problem.\n",
        "> - Use activation functions after each layer to introduce non-linearity.\n",
        "> - Experiment with different layer types and configurations to find the best architecture for your problem.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUFwWIR74ZR3",
        "outputId": "94b8429d-c85b-42c4-b805-a75b4e37e327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§  Quiz 3: Understanding Network Width for Inverse Kinematics\n",
            "--------------------------------------------------------------------------------\n",
            "ðŸ“‹ Neural Network Width Quiz\n",
            "--------------------------------------------------------------------------------\n",
            "For the robot arm inverse kinematics regression problem, which statement about network width (number of neurons in hidden layers) is most accurate?\n",
            "\n",
            "A. A single neuron in each hidden layer is sufficient since this is a simple regression task\n",
            "\n",
            "B. The number of neurons should exactly match the number of input features (6)\n",
            "\n",
            "C. The hidden layers should have more neurons than inputs to capture complex spatial relationships\n",
            "\n",
            "D. The hidden layers should have fewer neurons than the output to prevent overfitting\n",
            "\n",
            "E. The width of the network doesn't impact performance, only the depth matters\n",
            "\n",
            "Enter your answer (A, B, C, etc.): A\n",
            "\n",
            "âŒ Incorrect. The correct answer is C.\n",
            "\n",
            "ðŸ“š Explanation:\n",
            "The hidden layers should have more neurons than inputs to capture complex\n",
            "spatial relationships in the robot arm kinematics problem. This is because:  1.\n",
            "Inverse kinematics involves complex non-linear relationships between end-\n",
            "effector positions and joint angles 2. The mapping from 6D input space (position\n",
            "and orientation) to 5D output space (joint angles) requires learning complex\n",
            "mathematical transformations 3. With too few neurons, the network would suffer\n",
            "from high bias (underfitting) 4. The number of neurons doesn't need to match the\n",
            "input or output dimensions exactly 5. While having too many neurons can lead to\n",
            "overfitting, techniques like regularization and dropout can help mitigate this\n",
            "A common practice is to start with more neurons than inputs and gradually adjust\n",
            "based on validation performance.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ðŸ§  Quiz 4: Understanding Network Depth for Inverse Kinematics\n",
            "--------------------------------------------------------------------------------\n",
            "ðŸ“‹ Network Depth for Inverse Kinematics\n",
            "--------------------------------------------------------------------------------\n",
            "When designing a neural network for robot arm inverse kinematics, which statement about network depth (number of hidden layers) is most accurate?\n",
            "\n",
            "A. A single hidden layer is always sufficient for any regression problem\n",
            "\n",
            "B. Deeper networks are always better than shallow ones for inverse kinematics\n",
            "\n",
            "C. Multiple hidden layers help capture hierarchical relationships in joint movements\n",
            "\n",
            "D. Deeper networks train faster than shallow networks\n",
            "\n",
            "E. The number of hidden layers should match the number of robot joints\n",
            "\n",
            "Enter your answer (A, B, C, etc.): C\n",
            "\n",
            "âœ… Correct!\n",
            "\n",
            "ðŸ“š Explanation:\n",
            "Multiple hidden layers help capture hierarchical relationships in joint\n",
            "movements. This is because:  1. Inverse kinematics involves complex geometric\n",
            "and spatial transformations that benefit from hierarchical representations 2.\n",
            "The first few layers might learn basic spatial features while deeper layers\n",
            "combine these into more complex movement patterns 3. With a single hidden layer,\n",
            "the model might struggle to approximate the complex non-linear relationship\n",
            "between end-effector positions and joint configurations 4. However, very deep\n",
            "networks may be prone to training difficulties like vanishing gradients 5. The\n",
            "optimal depth depends on the complexity of the specific robot's kinematic chain,\n",
            "not just the number of joints  Depth should be chosen based on the complexity of\n",
            "the task and validated empirically, not based on arbitrary rules.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ðŸ§  Quiz 5: Regularization Techniques for Kinematics Models\n",
            "--------------------------------------------------------------------------------\n",
            "ðŸ“‹ Regularization Techniques for Kinematics Models\n",
            "--------------------------------------------------------------------------------\n",
            "Which regularization technique would be most effective for improving generalization in a neural network for robot arm inverse kinematics?\n",
            "\n",
            "A. Using only linear layers without any non-linear activations\n",
            "\n",
            "B. Implementing dropout between layers during training\n",
            "\n",
            "C. Limiting training to exactly 10 epochs\n",
            "\n",
            "D. Using MSE loss instead of MAE loss\n",
            "\n",
            "E. Removing all hidden layers to simplify the model\n",
            "\n",
            "Enter your answer (A, B, C, etc.): D\n",
            "\n",
            "âŒ Incorrect. The correct answer is B.\n",
            "\n",
            "ðŸ“š Explanation:\n",
            "Implementing dropout between layers during training is most effective because:\n",
            "1. Dropout randomly deactivates a percentage of neurons during each training\n",
            "step, which prevents neurons from co-adapting too much 2. This forces the\n",
            "network to learn redundant representations of the kinematic relationships 3. The\n",
            "model becomes more robust to variations in input positions and orientations 4.\n",
            "Dropout acts like an ensemble of different network architectures, improving\n",
            "generalization 5. It helps prevent overfitting when the network needs to be\n",
            "expressive (with many parameters) to capture the complex mapping  For robot arm\n",
            "inverse kinematics, good generalization is critical since the robot needs to\n",
            "perform reliably across the entire workspace, even in positions not exactly\n",
            "represented in the training data.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Quiz 3: Network Width\n",
        "print(\"\\nðŸ§  Quiz 3: Understanding Network Width for Inverse Kinematics\")\n",
        "quizzer.run_quiz(3)\n",
        "\n",
        "# Quiz 4: Network Depth\n",
        "print(\"\\nðŸ§  Quiz 4: Understanding Network Depth for Inverse Kinematics\")\n",
        "quizzer.run_quiz(4)\n",
        "\n",
        "# Quiz 5: Regularization Techniques\n",
        "print(\"\\nðŸ§  Quiz 5: Regularization Techniques for Kinematics Models\")\n",
        "quizzer.run_quiz(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVY0CYnE4ZR3"
      },
      "source": [
        "### Initialising Weights and Biases\n",
        "***\n",
        "\n",
        "In the previous session we looked at the concept of weights and biases. With our Perceptron we initialised the weights and biases to random values. In PyTorch, we can use different methods to initialise the weights and biases of a neural network.\n",
        "\n",
        "The importance of initialising weights and biases lies in the fact that they can significantly affect the convergence speed and performance of the neural network. Proper initialisation can help prevent issues such as vanishing or exploding gradients, which can hinder the training process.\n",
        "\n",
        "| Initialisation Method | Formula | PyTorch Code | Description |\n",
        "|-----------------------|----------|--------------|-------------|\n",
        "| Xavier/Glorot Initialisation | $\\displaystyle W \\sim \\mathcal{U}(-\\sqrt{\\frac{6}{n_{in} + n_{out}}}, \\sqrt{\\frac{6}{n_{in} + n_{out}}})$ | `torch.nn.init.xavier_uniform_(tensor)` | Suitable for sigmoid and tanh activations. |\n",
        "| He Initialisation | $\\displaystyle W \\sim \\mathcal{U}(-\\sqrt{\\frac{6}{n_{in}}}, \\sqrt{\\frac{6}{n_{in}}})$ | `torch.nn.init.kaiming_uniform_(tensor)` | Suitable for ReLU activations. |\n",
        "| Kaiming Normal Initialisation | $\\displaystyle W \\sim \\mathcal{N}(0, \\sqrt{\\frac{2}{n_{in}}})$ | `torch.nn.init.kaiming_normal_(tensor)` | Suitable for ReLU activations. |\n",
        "| Kaiming Uniform Initialisation | $\\displaystyle W \\sim \\mathcal{U}(-\\sqrt{\\frac{6}{n_{in}}}, \\sqrt{\\frac{6}{n_{in}}})$ | `torch.nn.init.kaiming_uniform_(tensor)` | Suitable for ReLU activations. |\n",
        "| Zero Initialisation | $\\displaystyle W = 0$ | `torch.nn.init.zeros_(tensor)` | All weights are set to zero. Not recommended. |\n",
        "| Random Initialisation | $\\displaystyle W \\sim \\mathcal{U}(-1, 1)$ | `torch.nn.init.uniform_(tensor)` | Weights are randomly initialised between -1 and 1. |\n",
        "\n",
        "***\n",
        "\n",
        "> <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/reminder.svg\" width=\"20\"/> **Tips**:\n",
        "> - Use Xavier or He initialisation for most cases, as they are designed to maintain the variance of activations across layers.\n",
        "> - Avoid zero initialisation, as it can lead to symmetry problems where all neurons learn the same features.\n",
        "> - PyTorch uses Kaiming initialisation by default for `torch.nn.Linear` layers, which is suitable for ReLU activations.\n",
        "> - Experiment with different initialisation methods to see their impact on training speed and model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxNU2xhz4ZR3",
        "outputId": "ce371cdc-e33c-482d-c745-3ca2f9fa7747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RobotArmNetwork(\n",
            "  (fc1): Linear(in_features=6, out_features=16, bias=True)\n",
            "  (hidden_activation): ReLU()\n",
            "  (fc2): Linear(in_features=16, out_features=5, bias=True)\n",
            ")\n",
            "\n",
            "Weight initialization validation:\n",
            "First layer weight stats: mean=0.0922, std=0.4984\n",
            "First layer bias: mean=0.0000, std=0.0000\n",
            "Output layer weight stats: mean=0.0406, std=0.3244\n",
            "Output layer bias: mean=0.0000, std=0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "âœ… model is correct!\n",
            "âœ… input_layer_size is correct!\n",
            "âœ… output_layer_size is correct!\n",
            "âœ… activation_type is correct!\n",
            "âœ… fc1_weight_stats is correct!\n",
            "âœ… fc2_weight_stats is correct!\n",
            "âœ… fc1_bias_stats is correct!\n",
            "âœ… fc2_bias_stats is correct!\n",
            "\n",
            "ðŸŽ‰ Excellent! All parts are correct!\n"
          ]
        }
      ],
      "source": [
        "# Exercise 2: Model Creation with Weight Initialization ðŸŽ¯\n",
        "# In this exercise, you will:\n",
        "# 1. Create a simple neural network model using PyTorch\n",
        "# 2. Initialize weights and biases properly\n",
        "# 3. Define layers with appropriate activation functions\n",
        "# 4. Implement a forward method\n",
        "\n",
        "class RobotArmNetwork(torch.nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
        "        \"\"\"Initialize a neural network for robotic arm inverse kinematics\n",
        "\n",
        "        Args:\n",
        "            input_size: Number of input features\n",
        "            hidden_size: Number of neurons in the hidden layer\n",
        "            output_size: Number of output features\n",
        "        \"\"\"\n",
        "        # Initialize the parent class\n",
        "        super().__init__()\n",
        "\n",
        "        # Define the layers of your neural network (simple architecture to avoid overfitting)\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "        self.hidden_activation = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # Initialize the weights using appropriate initialization techniques\n",
        "        # He/Kaiming initialization for layers with ReLU activation\n",
        "        torch.nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
        "        torch.nn.init.zeros_(self.fc1.bias)\n",
        "\n",
        "        # Xavier/Glorot initialization for the output layer\n",
        "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        torch.nn.init.zeros_(self.fc2.bias)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass through the network\"\"\"\n",
        "        # Process input through first fully connected layer and activation function\n",
        "        x = self.hidden_activation(self.fc1(x))\n",
        "\n",
        "        # Process through output layer (no activation - we want raw values for regression)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Initialize your model with appropriate dimensions\n",
        "model = RobotArmNetwork(input_size=6, hidden_size=16, output_size=5)\n",
        "\n",
        "# Print your model architecture\n",
        "print(model)\n",
        "\n",
        "# Print weight statistics to verify initialization\n",
        "print(\"\\nWeight initialization validation:\")\n",
        "print(f\"First layer weight stats: mean={model.fc1.weight.mean().item():.4f}, std={model.fc1.weight.std().item():.4f}\")\n",
        "print(f\"First layer bias: mean={model.fc1.bias.mean().item():.4f}, std={model.fc1.bias.std().item():.4f}\")\n",
        "print(f\"Output layer weight stats: mean={model.fc2.weight.mean().item():.4f}, std={model.fc2.weight.std().item():.4f}\")\n",
        "print(f\"Output layer bias: mean={model.fc2.bias.mean().item():.4f}, std={model.fc2.bias.std().item():.4f}\")\n",
        "\n",
        "# âœ… Check your answer\n",
        "answer = {\n",
        "    'model': model,\n",
        "    'input_layer_size': model.fc1.in_features,\n",
        "    'output_layer_size': model.fc2.out_features,\n",
        "    'activation_type': model.hidden_activation.__class__,\n",
        "    'fc1_weight_stats': {\n",
        "        'mean': model.fc1.weight.mean().item(),\n",
        "        'std': model.fc1.weight.std().item()\n",
        "    },\n",
        "    'fc2_weight_stats': {\n",
        "        'mean': model.fc2.weight.mean().item(),\n",
        "        'std': model.fc2.weight.std().item()\n",
        "    },\n",
        "    'fc1_bias_stats': {\n",
        "        'mean': model.fc1.bias.mean().item(),\n",
        "        'std': model.fc1.bias.std().item()\n",
        "    },\n",
        "    'fc2_bias_stats': {\n",
        "        'mean': model.fc2.bias.mean().item(),\n",
        "        'std': model.fc2.bias.std().item()\n",
        "    }\n",
        "}\n",
        "checker.check_exercise(2, answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIkF5aXP4ZR3"
      },
      "source": [
        "## Step 6: Choose Optimiser\n",
        "***\n",
        "> <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/write.svg\" width=\"20\"/> **Definition**: Optimisers are algorithms used to update the model parameters during training to minimise the loss function.\n",
        "\n",
        "The next step is to choose an optimiser for the model.\n",
        "\n",
        "The optimiser algorithm is used to update the model parameters during training. Most optimizers use a version of gradient descent to update the model parameters. The goal of the optimiser is to minimize the loss function by adjusting the weights and biases of the model. The most commonly used optimizers include:\n",
        "\n",
        "| Optimizer | PyTorch Implementation | Best Used For |\n",
        "|-----------|---------------------|--------------|\n",
        "| Stochastic Gradient Descent (SGD) | `torch.optim.SGD(params, lr)` | Simple problems, good with momentum |\n",
        "| Adam | `torch.optim.Adam(params, lr)` | Most deep learning tasks |\n",
        "| RMSProp | `torch.optim.RMSprop(params, lr)` | Deep neural networks |\n",
        "| Adagrad | `torch.optim.Adagrad(params, lr)` | Sparse data tasks |\n",
        "| AdamW | `torch.optim.AdamW(params, lr)` | When regularization is important |\n",
        "\n",
        "The Adam optimiser is a popular choice for training deep learning models due to its efficiency and effectiveness. It combines the benefits of both SGD and RMSProp, making it suitable for a wide range of tasks.\n",
        "\n",
        "### Learning Rate\n",
        "***\n",
        "The learning rate is a hyperparameter that determines the step size at each iteration while moving toward a minimum of the loss function. A small learning rate may lead to slow convergence, while a large learning rate may cause the model to diverge. It is important to choose an appropriate learning rate for the optimizer to work effectively\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/learning_rate.png\" width=\"50%\">\n",
        "</div>\n",
        "\n",
        "## Step 7: Choose Loss Function\n",
        "***\n",
        "The next step is to choose a loss function for the model. The choice of loss function depends on the type of problem being solved. The loss function measures how well the model is performing and guides the optimisation process. The most commonly used loss functions include:\n",
        "\n",
        "| Loss Function | PyTorch Implementation | Best Used For |\n",
        "|---------------|---------------------|--------------|\n",
        "| Mean Squared Error (MSE) | `torch.nn.MSELoss()` | Regression tasks |\n",
        "| Mean Absolute Error (MAE) | `torch.nn.L1Loss()` | Regression tasks |\n",
        "| Binary Cross-Entropy | `torch.nn.BCELoss()` | Binary classification tasks |\n",
        "| Categorical Cross-Entropy | `torch.nn.CrossEntropyLoss()` | Multi-class classification tasks |\n",
        "| Hinge Loss | `torch.nn.HingeEmbeddingLoss()` | Support Vector Machines (SVM) |\n",
        "| Kullback-Leibler Divergence | `torch.nn.KLDivLoss()` | Probabilistic models |\n",
        "\n",
        "The loss works in conjunction with the optimiser. While there are loss functions that can work for the same task, the choice of loss will have an effect on the final performance of the model. For instance, using MSE (L2-Norm) loss for a regression task will penalise larger errors more than smaller ones, while MAE (L1-Norm) loss treats all errors equally. This can lead to different model performance depending on the distribution of the data.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/losses.png\" width=\"60%\">\n",
        "</div>\n",
        "\n",
        "***\n",
        "\n",
        "> <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/reminder.svg\" width=\"20\"/> **Tips**:\n",
        "> - Choose a loss function that is appropriate for the type of problem being solved (e.g., regression, classification).\n",
        "> - Monitor the loss during training to ensure that the model is converging and not overfitting.\n",
        "> - Experiment with different loss functions to see their impact on model performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS9wUkVW4ZR4",
        "outputId": "e2f5ae61-76e3-439a-bd35-99a803ffaeda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: Adam\n",
            "Learning rate: 0.001\n",
            "Loss function: MSELoss\n",
            "--------------------------------------------------------------------------------\n",
            "âœ… optimizer_type is correct!\n",
            "âœ… learning_rate is correct!\n",
            "âœ… loss_function_type is correct!\n",
            "\n",
            "ðŸŽ‰ Excellent! All parts are correct!\n"
          ]
        }
      ],
      "source": [
        "# Exercise 3: Optimizer and Loss Function Selection ðŸŽ¯\n",
        "# In this exercise, you will:\n",
        "# 1. Select an appropriate optimizer for your model\n",
        "# 2. Choose a suitable loss function\n",
        "# 3. Set the learning rate\n",
        "\n",
        "# Create an Adam optimizer for your model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Create a Mean Squared Error loss function\n",
        "loss_function = torch.nn.MSELoss()\n",
        "\n",
        "# Store the optimizer and loss function in the model for easy access\n",
        "model.optimizer = optimizer\n",
        "model.loss_function = loss_function\n",
        "\n",
        "# Print the optimizer and loss function configuration\n",
        "print(f\"Optimizer: {type(model.optimizer).__name__}\")\n",
        "print(f\"Learning rate: {model.optimizer.param_groups[0]['lr']}\")\n",
        "print(f\"Loss function: {type(model.loss_function).__name__}\")\n",
        "\n",
        "# âœ… Check your answer\n",
        "answer = {\n",
        "    'optimizer_type': type(optimizer),\n",
        "    'learning_rate': optimizer.param_groups[0]['lr'],\n",
        "    'loss_function_type': type(loss_function)\n",
        "}\n",
        "checker.check_exercise(3, answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za6k_6Yk4ZR4"
      },
      "source": [
        "## Step 8 and 9: Create Training Loop and Fit Model\n",
        "***\n",
        "The training loop implements the key steps for training a neural network model:\n",
        "\n",
        "| Step | Description | Code Example |\n",
        "|------|-------------|--------------|\n",
        "| 1. Forward Pass | Pass input data through model to generate predictions | `predictions = model(inputs)` |  \n",
        "| 2. Loss Computation | Calculate loss between predictions and targets | `loss = criterion(predictions, targets)` |\n",
        "| 3. Backward Pass | Compute gradients through backpropagation | `loss.backward()` |\n",
        "| 4. Parameter Updates | Update model parameters using optimizer | `optimizer.step()` |\n",
        "| 5. Gradient Reset | Zero out gradients for next iteration | `optimizer.zero_grad()` |\n",
        "\n",
        "The next step is to fit the model using the training data. The model is trained for a specified number of epochs, and the training and validation loss is monitored during training. The number of epochs is a hyperparameter that determines how many times the model will be trained on the entire training dataset.\n",
        "\n",
        "***\n",
        "\n",
        "> <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/code.svg\" width=\"20\"/> **Snippet 2**: Training Loop Structure\n",
        "\n",
        "```python\n",
        "for epoch in range(num_epochs):\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # 1. Forward Pass\n",
        "    predictions = model(inputs)\n",
        "    \n",
        "    # 2. Loss Computation\n",
        "    loss = criterion(predictions, targets)\n",
        "    \n",
        "    # 3. Backward Pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # 4. Parameter Updates\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 5. Gradient Reset\n",
        "    optimizer.zero_grad()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb5xAWGy4ZR4"
      },
      "outputs": [],
      "source": [
        "# Exercise 4: Creating a Training Loop ðŸŽ¯\n",
        "# In this exercise, you will:\n",
        "# 1. Create a training loop for your neural network\n",
        "# 2. Implement forward and backward passes\n",
        "# 3. Monitor training and validation loss\n",
        "\n",
        "def train_model(model,\n",
        "                train_features,\n",
        "                train_targets,\n",
        "                val_features,\n",
        "                val_targets,\n",
        "                epochs=100):\n",
        "    \"\"\"\n",
        "    Train a neural network model\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model to train\n",
        "        train_features: Training features\n",
        "        train_targets: Training targets\n",
        "        val_features: Validation features\n",
        "        val_targets: Validation targets\n",
        "        epochs: Number of training epochs\n",
        "\n",
        "    Returns:\n",
        "        train_losses: List of training losses\n",
        "        val_losses: List of validation losses\n",
        "    \"\"\"\n",
        "    # Initialize lists to store losses\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    # Put model in training mode\n",
        "    # Your code here\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "        # 1. Zero gradients\n",
        "        # Your code here\n",
        "\n",
        "        # 2. Forward pass\n",
        "        predictions = # Your code here\n",
        "\n",
        "        # 3. Compute loss\n",
        "        loss = # Your code here\n",
        "\n",
        "        # 4. Backward pass\n",
        "        # Your code here\n",
        "\n",
        "        # 5. Update weights\n",
        "        # Your code here\n",
        "\n",
        "        # 6. Store training loss\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # 7. Compute validation loss\n",
        "        model.eval() # Set model to evaluation mode\n",
        "        with torch.no_grad(): # No need to track gradients for validation\n",
        "            val_predictions = model(val_features)\n",
        "            val_loss = model.loss_function(val_predictions, val_targets).item()\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "        # Set model back to training mode\n",
        "        model.train()\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# Run training for 100 epochs\n",
        "train_losses, val_losses = train_model(\n",
        "    model=model,\n",
        "    train_features=X_train_scaled,\n",
        "    train_targets=y_train_scaled,\n",
        "    val_features=X_val_scaled,\n",
        "    val_targets=y_val_scaled,\n",
        "    epochs=300\n",
        ")\n",
        "\n",
        "# Plot training and validation loss\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.plot(train_losses, label='Train Loss')\n",
        "ax.plot(val_losses, label='Validation Loss')\n",
        "utils.plotting.make_fig_pretty(ax, title='Loss vs Epochs', xlabel='Epochs', ylabel='Loss',ctab=True)\n",
        "plt.show()\n",
        "\n",
        "# âœ… Check your answer\n",
        "answer = {\n",
        "    'train_losses': train_losses[-1],\n",
        "    'val_losses': val_losses[-1],\n",
        "    'loss_trend': train_losses[0] > train_losses[-1],\n",
        "    'overfit_check': val_losses[-1] <= val_losses[0] * 1.5  # Should not have increased much\n",
        "}\n",
        "checker.check_exercise(4, answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-7xm_1u4ZR4"
      },
      "source": [
        "### Overfitting, Underfitting, and Early Stopping\n",
        "***\n",
        "> <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/write.svg\" width=\"20\"/> **Definition**: Overfitting occurs when a model learns the training data too well, including noise and outliers, leading to poor generalisation on unseen data. Underfitting occurs when a model is too simple to capture the underlying patterns in the data.\n",
        "\n",
        "As we can see in the following figure, the training loss decreases over time, while the validation loss follows a similar trend. However, the validation loss starts to slowly deviate from the training loss after a certain number of epochs. This indicates that the model is starting to overfit the training data. The point at which the validation loss starts to increase is known as the \"early stopping\" point. This is the point at which we should stop training the model to prevent overfitting.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/over_under_fit.png\" width=\"70%\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQwFHIt14ZR5"
      },
      "source": [
        "## Step 10: Evaluate Model\n",
        "***\n",
        "The next step is to evaluate the model using the validation and test data. The model is evaluated on the validation set during training to monitor its performance and prevent overfitting.\n",
        "\n",
        "Since we are training a model with MSE loss, we can also plot the predicted output against the actual output to see how well the model is performing. The predicted output should be close to the actual output, and the points should be clustered around the diagonal line. If the points are scattered far from the diagonal line, it indicates that the model is not performing well.\n",
        "\n",
        "We can also compute the R-squared value to quantify the performance of the model. The R-squared value is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. The R-squared value ranges from 0 to 1, where 0 indicates that the model does not explain any of the variance in the data, and 1 indicates that the model explains all of the variance in the data.\n",
        "\n",
        "For this step we are going to use the test set to evaluate the model.\n",
        "\n",
        "***\n",
        "> <img src=\"https://github.com/CLDiego/uom_fse_dl_workshop/raw/main/figs/icons/code.svg\" width=\"20\"/> **Snippet 3**: Evaluate Model\n",
        "\n",
        "```python\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Disable gradient calculation\n",
        "with torch.no_grad():\n",
        "    # Forward pass through the model\n",
        "    predictions = model(inputs)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(predictions, targets)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHotf_Um4ZR5"
      },
      "outputs": [],
      "source": [
        "# Exercise 5: Model Evaluation ðŸŽ¯\n",
        "# In this exercise, you will:\n",
        "# 1. Evaluate your trained model on the test set\n",
        "# 2. Calculate R-squared score to measure model performance\n",
        "# 3. Visualize actual vs. predicted values for one joint\n",
        "\n",
        "# Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Predict on the test set without computing gradients\n",
        "with torch.no_grad():\n",
        "    test_predictions = # Your code here\n",
        "\n",
        "    # Calculate the test loss\n",
        "    test_loss = # Your code here\n",
        "\n",
        "    # Convert predictions and targets back to original scale\n",
        "    test_predictions_original = # Your code here\n",
        "    test_targets_original = # Your code here\n",
        "\n",
        "# Calculate the R-squared score\n",
        "r2_score = utils.ml.r2_score(test_targets_original, test_predictions_original)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "print(f\"R-squared Score: {r2_score:.4f}\")\n",
        "\n",
        "# Visualize actual vs. predicted values for the shoulder pitch joint (first joint)\n",
        "fig, axes = plt.subplots(figsize=(16, 20), nrows=5)\n",
        "\n",
        "for ix, joint in enumerate(y_test.columns):\n",
        "    axes[ix].plot(test_targets_original[:, ix], test_predictions_original[:, ix], 'o', fillstyle='none', markersize=2)\n",
        "    axes[ix].plot(test_targets_original[:, ix], test_targets_original[:, ix], 'r--')\n",
        "\n",
        "    utils.plotting.make_fig_pretty(axes[ix], title=f\"{joint}\", ylabel='Predicted',\n",
        "                                   xtick_fsize=10, ytick_fsize=10,\n",
        "                                   title_fsize=12, xlabel_fsize=10)\n",
        "\n",
        "    if ix == 4:\n",
        "        axes[ix].set_xlabel('ACTUAL')\n",
        "\n",
        "\n",
        "\n",
        "# âœ… Check your answer\n",
        "answer = {\n",
        "    'test_loss': test_loss.item(),\n",
        "    'r2_score': r2_score,\n",
        "    'predictions_shape': test_predictions_original.shape,\n",
        "    'values_match': test_predictions_original.shape == test_targets_original.shape\n",
        "}\n",
        "checker.check_exercise(5, answer)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}